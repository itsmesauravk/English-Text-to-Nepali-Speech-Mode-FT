{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae7d0c1",
   "metadata": {},
   "source": [
    "## 2. Text (Nepali) to Speech (Nepali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c17dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import VitsModel, AutoTokenizer\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import Optional, List\n",
    "import os\n",
    "import logging \n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3371f4",
   "metadata": {},
   "source": [
    "Logging is better then 'print' function for debugging/tracing\n",
    "\n",
    "- Control level \n",
    "1. show only what we want (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "2. can include module name, timestamp, line numbers\n",
    "\n",
    "More professional then print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45eb7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e29b65fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9097/3708429370.py:10: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator('text')\n"
     ]
    }
   ],
   "source": [
    "class TTSRequest(BaseModel):\n",
    "    \"\"\"Request model for TTS generation\"\"\"\n",
    "    text: str = Field(..., min_length=1, max_length=1000, description=\"Text to convert to speech\")\n",
    "    speed: float = Field(default=1.0, ge=0.5, le=2.0, description=\"Speech speed multiplier\")\n",
    "    emotion: Optional[str] = Field(default=\"neutral\", description=\"Emotion context\")\n",
    "    is_emergency: bool = Field(default=False, description=\"Emergency speech (will effect tone and clarity)\")\n",
    "    preserve_prosody: bool = Field(default=True, description=\"Preserve natural speech prosody\")\n",
    "\n",
    "\n",
    "    @validator('text')\n",
    "    def validate_text(cls, v):\n",
    "        if not v.strip():\n",
    "            raise ValueError(\"Text cannot be empty or whitespace\")\n",
    "        \n",
    "        return v.strip()\n",
    "    \n",
    "\n",
    "class TTSResponse(BaseModel):\n",
    "    \"\"\"Respnse model for TTS generation\"\"\"\n",
    "    original_text: str\n",
    "    audio_file_path: str\n",
    "    sample_rate: int\n",
    "    duration_second: float\n",
    "    model_used: str\n",
    "    generation_time: float\n",
    "    metadata: dict = {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bc184bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NepaliTTSSystem:\n",
    "    \"\"\"Nepali Text to Speech conversion system using VITS model\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_name: str = \"tuskbyte/nepali_male_v1\",\n",
    "                 cache_dir: Optional[str] = None,\n",
    "                 device: Optional[str] = None\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initialize the Nepali TTS system.\n",
    "\n",
    "        Args:\n",
    "            model_name: Hugging face model identifier.\n",
    "            cache_dir: Directory to cache downloaded models\n",
    "            device: Device to run the model on ('cpu' or 'cuda'). If None, auto-detect.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        # self.cache_dir = cache_dir or os.path.expanduser(\"~/.cache/nepali_tts\")\n",
    "        self.cache_dir = cache_dir or \"./audio_tts\"\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "\n",
    "        # self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = 'cpu'\n",
    "\n",
    "        # creating cache directory\n",
    "        Path(self.cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        logger.info(f\"Initializing TTS system with model: {self.model_name} on device: {self.device}\")\n",
    "\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self._load_model()\n",
    "\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the VITS models and its tokenizer\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Loading tokenizer...\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name,\n",
    "                cache_dir=self.cache_dir\n",
    "            )\n",
    "\n",
    "            logger.info(\"Loading TTS model...\")\n",
    "            self.model = VitsModel.from_pretrained(\n",
    "                self.model_name,\n",
    "                cache_dir=self.cache_dir\n",
    "            )\n",
    "\n",
    "            # set to evaluation model for inference\n",
    "            self.model.eval()\n",
    "            logger.info(\"Model and tokenizer loaded successfully!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load model or tokenizer: {e}\")\n",
    "            raise RuntimeError(f\"Failed to initialize TTS model: {e}\")\n",
    "\n",
    "        \n",
    "    \n",
    "    def _preprocess_text(self, text: str, is_emergency: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        Preprocess text for better TTS output\n",
    "        Args:\n",
    "            text: Input text\n",
    "            is_emergency: Whether this is emergency speech\n",
    "        Returns:\n",
    "            Preprocessed text\n",
    "        \"\"\"\n",
    "\n",
    "        #applying basic normalization\n",
    "        text = text.strip()\n",
    "\n",
    "        #for emergency speech, add emphasis markes \n",
    "        if is_emergency:\n",
    "          # adding pauses for clarity in emergency situations\n",
    "          text = text.replace(\"।\", \"। \")  # add space after nepali full stop\n",
    "          text = text.replace(\"?\", \"? \")   # add space after question mark\n",
    "          text = text.replace(\"!\", \"! \")   # add space after exclamation\n",
    "\n",
    "        return text\n",
    "\n",
    "    \n",
    "    def generate_speech(self, request: TTSRequest) -> TTSResponse:\n",
    "        \"\"\"\n",
    "        Generate speech from text using VITS model.\n",
    "        Args:\n",
    "            request: TTSRequest object with generation parameters\n",
    "        Returns:\n",
    "            TTSResponse with audio file path and metadata\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        try:\n",
    "            # preprocess text\n",
    "            preprocessed_text = self._preprocess_text(request.text, request.is_emergency)\n",
    "            logger.info(f\"Preprocessed text: {preprocessed_text}\")\n",
    "\n",
    "            # Tokenize input\n",
    "            # inputs = self.tokenizer(preprocessed_text, return_tensor='pt').to(self.device)\n",
    "            # updated\n",
    "            inputs = self.tokenizer(\n",
    "                preprocessed_text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "\n",
    "            # Move to device properly\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "\n",
    "            # Generate speech\n",
    "            with torch.no_grad():\n",
    "                #setting seed for reproducible result\n",
    "                if hasattr(self.model.config, \"use_stochastic_duration_prediction\"):\n",
    "                    torch.manual_seed(42)\n",
    "\n",
    "                output = self.model(**inputs,)\n",
    "                waveform = output.waveform.squeeze().cpu().numpy() #numpy because easy to pass value to (librosa, soundfile, scipy)\n",
    "                #for pytorch \n",
    "                # waveform = output.waveform.squeeze().cpu()\n",
    "            \n",
    "            if request.speed != 1.0:\n",
    "                waveform  = self._modify_speed(waveform, request.speed)\n",
    "            \n",
    "            #saveing audio file\n",
    "            output_path = self._save_audio(\n",
    "                waveform, \n",
    "                self.model.config.sampling_rate,\n",
    "                request.is_emergency\n",
    "            )\n",
    "\n",
    "            #calculationg duration\n",
    "            duration = len(waveform) / self.model.config.sampling_rate\n",
    "            generation_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "\n",
    "            return TTSResponse(\n",
    "                original_text=request.text,\n",
    "                audio_file_path=output_path,\n",
    "                sample_rate=self.model.config.sampling_rate,\n",
    "                duration_second=duration,\n",
    "                model_used=self.model_name,\n",
    "                generation_time=generation_time,\n",
    "                metadata={\n",
    "                    \"processed_text\": preprocessed_text,\n",
    "                    \"emotion\": request.emotion,\n",
    "                    \"is_emergency\": request.is_emergency,\n",
    "                    \"preserve_prosody\": request.preserve_prosody,\n",
    "                    \"speed\": request.speed\n",
    "                }\n",
    "\n",
    "            )\n",
    "          \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Speech generation failed: {e}\")\n",
    "            raise RuntimeError(f\"Failed to generate speech: {e}\")\n",
    "\n",
    "\n",
    "    def _modify_speed(self, waveform: np.ndarray, speed:float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Modify the speech speed using simple resampling.\n",
    "        Args:\n",
    "            waveform: Input audio waveform\n",
    "            speed: Speed multipler (>1 = faster, <1 = slower)\n",
    "        Returns:\n",
    "            Speed-modified waveform\n",
    "        \"\"\"\n",
    "        try:\n",
    "            new_length = int(len(waveform) / speed)\n",
    "            return signal.resample(waveform, new_length)\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to modify speed: {e}. Returning original waveform.\")\n",
    "            return waveform\n",
    "    \n",
    "\n",
    "    def _save_audio(self, waveform: np.ndarray, sample_rate: int, is_emergency:bool = False) -> str:\n",
    "        \"\"\"\n",
    "        Save audio waveform to file\n",
    "        Args:\n",
    "            waveform: Audio waveform\n",
    "            sample_rate: Sampling rate\n",
    "            is_emergency: Whether this is emergency speech (affects filename)\n",
    "        \"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        prefix = \"emergency_\" if is_emergency else \"speech_\"\n",
    "        filename = f\"{prefix}{timestamp}.wav\"\n",
    "\n",
    "        output_dir = Path(self.cache_dir) / \"generated_audio\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        output_path = output_dir / filename\n",
    "\n",
    "        # Ensure waveform is in correct format for spicy\n",
    "        if waveform.dtype != np.int16:\n",
    "            #converting to 19-bit PCM\n",
    "            waveform_int16 = (waveform * 32767).astype(np.int16)\n",
    "        else:\n",
    "            waveform_int16 = waveform\n",
    "        \n",
    "        scipy.io.wavfile.write(str(output_path), sample_rate, waveform_int16)\n",
    "\n",
    "        logger.info(f\"Audio saved to: {output_path}\")\n",
    "        return str(output_path)\n",
    "\n",
    "\n",
    "    def generate_simple(self, text: str, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Simple interface for TTS generation\n",
    "        Args:\n",
    "            text: Text to convert to speech\n",
    "            kwargs: Additional TTSRequest parameters (speed, emotion, etc.)\n",
    "        Returns:\n",
    "            Path to generated audio file\n",
    "        \"\"\"\n",
    "        request = TTSRequest(text=text, **kwargs)\n",
    "        response = self.generate_speech(request)\n",
    "\n",
    "        return response.audio_file_path\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a601471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usages \n",
    "class EmergencyTTS:\n",
    "    \"\"\"\n",
    "    Specialized TTS for emergency situations\n",
    "    \"\"\"\n",
    "    def __init__(self, tts_system: NepaliTTSSystem):\n",
    "        self.tts = tts_system\n",
    "\n",
    "        #common emergency phrases\n",
    "        self.emergency_phrases = {\n",
    "            \"police\": \"पुलिसलाई फोन गर्नुहोस्\",\n",
    "            \"ambulance\": \"एम्बुलेन्स बोलाउनुहोस्\",\n",
    "            \"fire\": \"दमकललाई फोन गर्नुहोस्\",\n",
    "            \"help\": \"मलाई मद्दत चाहिन्छ\",\n",
    "            \"emergency\": \"यो आपतकालिन अवस्था हो\"\n",
    "        }\n",
    "\n",
    "    \n",
    "    def generate_emergency_speech(self, text: str, phrase_type: Optional[str] = None) -> str:\n",
    "        \"\"\"Generate emergency speech with appropriate urgency and clarity\"\"\"\n",
    "\n",
    "        # adding context-appropriate prefix if phrase type is knows\n",
    "        if phrase_type and phrase_type in self.emergency_phrases:\n",
    "            text = f\"{self.emergency_phrases[phrase_type]}। {text}\"\n",
    "\n",
    "        request = TTSRequest(\n",
    "            text=text,\n",
    "            speed=0.9,  # slightly slower for clarity\n",
    "            is_emergency=True,\n",
    "            emotion=\"urgent\",\n",
    "        )\n",
    "\n",
    "        response = self.tts.generate_speech(request)\n",
    "\n",
    "        return response.audio_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9fb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
